{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from matplotlib import pyplot as plt \n",
    "import sklearn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data with pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_inputs = pd.read_csv('train_features.csv')\n",
    "training_labels = pd.read_csv('train_labels.csv')\n",
    "test_inputs = pd.read_csv('test_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort data according to the patient ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_inputs = training_inputs.sort_values(by=['pid','Time'])\n",
    "training_labels = training_labels.sort_values(by=['pid'])\n",
    "test_inputs = test_inputs.sort_values(by=['pid','Time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a vector containing the column labels of the feature vectors and the label vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = training_inputs.columns\n",
    "labels = training_labels.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the 12 observations for each patient in the training set and in the tesing set into a sigle observation by calculating the mean of the values that are not NaN. Next, replace all NaN with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test patients:  316536\r"
     ]
    }
   ],
   "source": [
    "# training set\n",
    "\n",
    "train_patients = training_inputs.loc[training_inputs['pid']==1].mean();\n",
    "\n",
    "for i in range(np.max(training_inputs['pid'])-1):\n",
    "\n",
    "    current_patient = training_inputs.loc[training_inputs['pid']==i+2].mean()  \n",
    "    \n",
    "    print('Train patients:  ' + str(i), end ='\\r')\n",
    "\n",
    "    #Some patient number are missing so we have to assert that the patient exists \n",
    "    \n",
    "    if np.isnan(current_patient.mean()) :\n",
    "        pass\n",
    "    else: \n",
    "         train_patients = np.vstack((train_patients,current_patient))\n",
    "            \n",
    "# testing set\n",
    "\n",
    "test_patients = test_inputs.loc[test_inputs['pid']==0].mean();\n",
    "\n",
    "\n",
    "for i in range(np.max(test_inputs['pid'])-1):\n",
    "\n",
    "    current_patient = test_inputs.loc[test_inputs['pid']==i+2].mean()\n",
    "\n",
    "    print('Test patients:  ' + str(i), end ='\\r')\n",
    "    \n",
    "    #Some patient number are missing so we have to assert that the patient exists \n",
    "    \n",
    "    if np.isnan(current_patient.mean()) :\n",
    "        pass\n",
    "    else: \n",
    "         test_patients = np.vstack((test_patients,current_patient))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create pandas dataframe for the training and the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use temporary variables not to mess up the original ones\n",
    "\n",
    "X_train = pd.DataFrame(train_patients, columns = features)\n",
    "X_test = pd.DataFrame(test_patients, columns = features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can compare the modified data with the original\n",
    "\n",
    "#k = 8 # k corresponds to the feature we are testing\n",
    "#j = 1000 # j corresponds to the patient \n",
    "#j = 12*j\n",
    "\n",
    "#test_inputs_old = pd.read_csv('test_features.csv')\n",
    "#test_inputs_old = test_inputs_old.sort_values(by=['pid','Time'])\n",
    "#print('Feature is: ' +str(features[k] + '\\n'))\n",
    "#print('Test input is: ' + '\\n\\n' + str(test_inputs_old[features[k]][j:j+12]) + '\\n')\n",
    "#print('Modified test input is: ' + str(X_test[features[k]][j/12]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove features with more than 85% of NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(features.shape[0]):\n",
    "    \n",
    "    # training set\n",
    "    \n",
    "    NAN_percentage = np.count_nonzero(np.isnan(train_patients[:,i]))/train_patients.shape[0]\n",
    "    if NAN_percentage > 0.85:\n",
    "        X_train = X_train.drop(columns=[features[i]])\n",
    "        \n",
    "    # test set\n",
    "        \n",
    "    NAN_percentage = np.count_nonzero(np.isnan(test_patients[:,i]))/test_patients.shape[0]\n",
    "    if NAN_percentage > 0.85:\n",
    "        X_test = X_test.drop(columns=[features[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now replace all remaining NaN with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, remove \"pid\" and \"time\" columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns=['pid', 'Time'])\n",
    "X_test = X_test.drop(columns=['pid', 'Time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtask 1\n",
    "\n",
    "Now that the preprocessing is finished, we can start training our estimators. First, import the necessay libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, create a vector containing all the labels we want to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_task1 = labels[1:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, generate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_pipeline(StandardScaler(), SVC(kernel='rbf',probability=True, class_weight='balanced'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the first prediction and initialize the vector that will contains all the predictions, initialize the vector containing the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 1 label out of 10, score is 0.9311783298054152\r"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train,training_labels[labels_task1[0]]) # fit\n",
    "\n",
    "probability = clf.predict_proba(X_train)[:,1] # compute probability\n",
    "\n",
    "task1_predictions = probability # here we will store all the predictions for task 1\n",
    "\n",
    "Score_task1 = roc_auc_score(training_labels[labels_task1[0]],probability) # here we will store the AUC for every prediction\n",
    "\n",
    "print('Done 1 label out of ' + str(labels_task1.shape[0]) + ', score is ' + str(Score_task1), end ='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the SVM and generate the AUC score, repeat this for all labels and store the predictions in the prediction vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 3 labels out of 10, score is [0.80849723]\r"
     ]
    }
   ],
   "source": [
    "for i in range(labels_task1.shape[0]-1):\n",
    "    \n",
    "    clf.fit(X_train,training_labels[labels_task1[i+1]]) # fit\n",
    "    \n",
    "    probability = clf.predict_proba(X_train)[:,1] # compute probability\n",
    "    \n",
    "    task1_predictions = np.vstack([task1_predictions,probability]) # add to prediction vector\n",
    "    \n",
    "    Score_task1 = np.vstack([Score_task1,roc_auc_score(training_labels[labels_task1[i+1]],probability)]) # compute AUC\n",
    "    \n",
    "    print('Done ' + str(i+2) + ' labels out of ' + str(labels_task1.shape[0]) + ', score is ' + str(Score_task1[i+1]), end ='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtask 2\n",
    "\n",
    "Now we predict the occurrence of sepsis. First create the vector containing the label we want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_task2 = labels[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train,training_labels[labels_task2]) # fit\n",
    "\n",
    "task2_predictions = clf.predict_proba(X_train)[:,1] # create prediction vector\n",
    "\n",
    "Score_task2 = roc_auc_score(training_labels[labels_task2],task2_predictions) # generate AUC\n",
    "\n",
    "print('Done, score is ' + str(Score_task2), end ='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtask 3\n",
    "\n",
    "We now want to predict the mean value of the vital sign in the remaining stay. First, let us create the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create feature vector and label vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs = training_labels.columns\n",
    "labels_task3 = training_labels[labs[12:16]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3 = make_pipeline(StandardScaler(), KernelRidge(alpha=0,kernel = 'rbf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the first prediction, compute the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3.fit(X_train,training_labels[labels_task3[0]]) # fit\n",
    "\n",
    "task3_predictions = clf3.predict(X_train) # predict\n",
    "\n",
    "MSE = mean_squared_error(training_labels[labels_task3[0]],task3_predictions,squared = True) # compute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(labels_task3.shape[0]-1):\n",
    "    \n",
    "    clf3.fit(X_train,training_labels[labels_task3[i+1]]) # fit\n",
    "    \n",
    "    prediction = clf3.predict(X_train) # predict\n",
    "    \n",
    "    task3_predictions = np.vstack([task3_predictions,prediction]) # add to prediction vector\n",
    "    \n",
    "    MSE = np.vstack([MSE,mean_squared_error(training_labels[labels_task3[i+1]],prediction,squared = True)]) # compute AUC\n",
    "    \n",
    "    print('Done ' + str(i+2) + ' predictions out of ' + str(labels_task3.shape[0]) + ', score is ' + str(MSE[i+1]), end ='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create solution and export to zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task1_trans = np.transpose(task1_predictions)\n",
    "Sol = training_labels\n",
    "# add probabilities of first task\n",
    "\n",
    "Sol[labels_task1]= task1_trans[:,0:10]\n",
    "\n",
    "# add probabilities of second task\n",
    "\n",
    "Sol[labels_task2] = task2_predictions[:]\n",
    "\n",
    "# add results of third task\n",
    "\n",
    "Sol[labels_task3] = task3_predictions[:,0:4]\n",
    "\n",
    "# export to zip file\n",
    "\n",
    "compression_opts = dict(method='zip',archive_name='Prediction.csv')\n",
    "Sol.to_csv('Prediction.csv', index=False, float_format='%.3f', compression='zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create ground truth from training labels csv file and export to zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_opts = dict(method='zip',archive_name='Truth.csv')\n",
    "training_labels.to_csv('Truth.zip', index=False, float_format='%.3f',compression=compression_opts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
