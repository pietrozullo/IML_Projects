{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from matplotlib import pyplot as plt \n",
    "import sklearn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data with pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_inputs = pd.read_csv('train_features.csv')\n",
    "training_labels = pd.read_csv('train_labels.csv')\n",
    "test_inputs = pd.read_csv('test_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a vector containing the column labels of the feature vectors and the label vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = training_inputs.columns\n",
    "labels = training_labels.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the 12 observations for each patient in the training set and in the tesing set into a sigle observation by calculating the mean of the values that are not NaN. Next, replace all NaN with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test patients:  126623\r"
     ]
    }
   ],
   "source": [
    "# training set\n",
    "\n",
    "train_patients = training_inputs[0:12].mean()\n",
    "\n",
    "for i in range(int(training_inputs.shape[0]/12)-1):\n",
    "\n",
    "    current_patient = training_inputs[(i+1)*12:(i+1)*12+12].mean()  \n",
    "    \n",
    "    print('Train patients:  ' + str(i), end ='\\r')\n",
    "\n",
    "    #Some patient number are missing so we have to assert that the patient exists \n",
    "    \n",
    "    if np.isnan(current_patient.mean()) :\n",
    "        pass\n",
    "    else: \n",
    "         train_patients = np.vstack((train_patients,current_patient))\n",
    "            \n",
    "# testing set\n",
    "\n",
    "test_patients = test_inputs[0:12].mean()\n",
    "\n",
    "\n",
    "for i in range(int(test_inputs.shape[0]/12)-1):\n",
    "\n",
    "    current_patient = test_inputs[(i+1)*12:(i+1)*12+12].mean()  \n",
    "\n",
    "    print('Test patients:  ' + str(i), end ='\\r')\n",
    "    \n",
    "    #Some patient number are missing so we have to assert that the patient exists \n",
    "    \n",
    "    if np.isnan(current_patient.mean()) :\n",
    "        pass\n",
    "    else: \n",
    "         test_patients = np.vstack((test_patients,current_patient))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create pandas dataframe for the training and the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use temporary variables not to mess up the original ones\n",
    "\n",
    "X_train = pd.DataFrame(train_patients, columns = features)\n",
    "X_test = pd.DataFrame(test_patients, columns = features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove features with more than 85% of NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(features.shape[0]):\n",
    "    \n",
    "    NAN_percentage = np.count_nonzero(np.isnan(test_patients[:,i]))/test_patients.shape[0]\n",
    "    if NAN_percentage > 0.85:\n",
    "        X_train = X_train.drop(columns=[features[i]])\n",
    "        X_test = X_test.drop(columns=[features[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now replace all remaining NaN with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, remove \"pid\" and \"time\" columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns=['pid', 'Time'])\n",
    "X_test = X_test.drop(columns=['pid', 'Time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtask 1\n",
    "\n",
    "Now that the preprocessing is finished, we can start training our estimators. First, import the necessay libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, create a vector containing all the labels we want to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_task1 = labels[1:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, generate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_pipeline(StandardScaler(), SVC(kernel='rbf',probability=True, class_weight='balanced'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the first prediction and initialize the vector that will contains all the predictions, initialize the vector containing the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 1 label out of 10\r"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train,training_labels[labels_task1[0]]) # fit\n",
    "\n",
    "probability = clf.predict_proba(X_test)[:,1] # compute probability\n",
    "\n",
    "task1_predictions = probability # here we will store all the predictions for task 1\n",
    "\n",
    "print('Done 1 label out of ' + str(labels_task1.shape[0]), end ='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the SVM and generate the AUC score, repeat this for all labels and store the predictions in the prediction vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 10 labels out of 10\r"
     ]
    }
   ],
   "source": [
    "for i in range(labels_task1.shape[0]-1):\n",
    "    \n",
    "    clf.fit(X_train,training_labels[labels_task1[i+1]]) # fit\n",
    "    \n",
    "    probability = clf.predict_proba(X_test)[:,1] # compute probability\n",
    "    \n",
    "    task1_predictions = np.vstack([task1_predictions,probability]) # add to prediction vector\n",
    "    \n",
    "    print('Done ' + str(i+2) + ' labels out of ' + str(labels_task1.shape[0]), end ='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtask 2\n",
    "\n",
    "Now we predict the occurrence of sepsis. First create the vector containing the label we want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_task2 = labels[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train,training_labels[labels_task2]) # fit\n",
    "\n",
    "task2_predictions = clf.predict_proba(X_test)[:,1] # create prediction vector\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtask 3\n",
    "\n",
    "We now want to predict the mean value of the vital sign in the remaining stay. First, let us create the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create feature vector and label vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_task3 = labels[12:16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3 = make_pipeline(StandardScaler(), KernelRidge(alpha=1.0,kernel = 'rbf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the first prediction, compute the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 1 predictions out of 4\n"
     ]
    }
   ],
   "source": [
    "clf3.fit(X_train,training_labels[labels_task3[0]]) # fit\n",
    "\n",
    "task3_predictions = clf3.predict(X_test) # predict\n",
    "\n",
    "print('Done 1 predictions out of ' + str(labels_task3.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 4 predictions out of 4\r"
     ]
    }
   ],
   "source": [
    "for i in range(labels_task3.shape[0]-1):\n",
    "    \n",
    "    clf3.fit(X_train,training_labels[labels_task3[i+1]]) # fit\n",
    "    \n",
    "    prediction = clf3.predict(X_test) # predict\n",
    "    \n",
    "    task3_predictions = np.vstack([task3_predictions,prediction]) # add to prediction vector\n",
    "    \n",
    "    print('Done ' + str(i+2) + ' predictions out of ' + str(labels_task3.shape[0]), end ='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create solution and export to zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose solutions to task 1 and 3 to match dimensions\n",
    "\n",
    "task1_trans = np.transpose(task1_predictions)\n",
    "task3_trans = np.transpose(task3_predictions)\n",
    "\n",
    "Prediction = pd.read_csv('Sample.zip') # initialize by using the sample submission\n",
    "\n",
    "# add probabilities of first task\n",
    "\n",
    "Prediction[labels_task1]= task1_trans[:,0:10]\n",
    "\n",
    "# add probabilities of second task\n",
    "\n",
    "Prediction[labels_task2] = task2_predictions[:]\n",
    "\n",
    "# add results of third task\n",
    "\n",
    "Prediction[labels_task3] = task3_trans[:,0:4]\n",
    "\n",
    "# export to zip file\n",
    "\n",
    "compression_opts = dict(method='zip',archive_name='Pred.csv')\n",
    "Prediction.to_csv('Pred.zip', index=False, float_format='%.3f', compression=compression_opts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
