{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from matplotlib import pyplot as plt \n",
    "import sklearn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data with pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_inputs = pd.read_csv(\"train_features.csv\")\n",
    "training_labels = pd.read_csv(\"train_labels.csv\")\n",
    "test_features = pd.read_csv(\"test_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort data according to the patient ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_inputs = training_inputs.sort_values(by=['pid'])\n",
    "training_labels = training_labels.sort_values(by=['pid'])\n",
    "test_features = test_features.sort_values(by = ['pid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a single label set called _labels clean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BaseExcess = training_labels['LABEL_BaseExcess']\n",
    "Fibrinogen = training_labels['LABEL_Fibrinogen']\n",
    "AST = training_labels['LABEL_AST']\n",
    "Alkalinephos = training_labels['LABEL_Alkalinephos']\n",
    "Bilirubin_total = training_labels['LABEL_Bilirubin_total']\n",
    "Lactate = training_labels['LABEL_Lactate']\n",
    "TroponinI = training_labels['LABEL_TroponinI']\n",
    "SaO2 = training_labels['LABEL_SaO2']\n",
    "Bilirubin_direct = training_labels['LABEL_Bilirubin_direct']\n",
    "EtCO2 = training_labels['LABEL_EtCO2']\n",
    "labels_clean = np.array([BaseExcess,Fibrinogen,AST,Alkalinephos,Bilirubin_total,Lactate,TroponinI,SaO2,Bilirubin_direct,EtCO2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of the features\n",
    "\n",
    "Replace NaN with zeros in both training and test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_inputs = training_inputs.fillna(0)\n",
    "test_features = test_features.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31656\r"
     ]
    }
   ],
   "source": [
    "#-------We first perform some data imputation with a pre built class from Sklearn ------- \n",
    "#The data imputation has to be done for each single patient so that values don't get mixed up\n",
    "#To do this we use the following loop\n",
    "#Define an empty array \n",
    "inputs = training_inputs\n",
    "patients = inputs.loc[inputs['pid']==1].mean();\n",
    "#Since some patients id do not exist the range is conservative\n",
    "for i in range(np.max(inputs['pid'])-1):\n",
    "    #First of all we split the data for a single patient\n",
    "    patient = inputs.loc[inputs['pid']==i+2].mean()\n",
    "    print(i,end ='\\r')\n",
    "    #Some patient number are missing so we have to assert that the patient exists \n",
    "    if np.isnan(patient.mean()) :\n",
    "        pass\n",
    "    else: \n",
    "         patients = np.vstack((patients,patient))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the same operation with the test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31653\r"
     ]
    }
   ],
   "source": [
    "#We do the same for test features\n",
    "inputs = test_features\n",
    "test_patients = inputs.loc[inputs['pid']==0].mean();\n",
    "#Since some patients id do not exist the range is conservative\n",
    "for i in range(np.max(inputs['pid'])-1):\n",
    "    #First of all we split the data for a single patient\n",
    "    test_patient = inputs.loc[inputs['pid']==i+2].mean()\n",
    "    print(i,end ='\\r')\n",
    "    #Some patient number are missing so we have to assert that the patient exists \n",
    "    if np.isnan(test_patient.mean()) :\n",
    "        pass\n",
    "    else: \n",
    "         test_patients = np.vstack((test_patients,test_patient))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop PID and Time columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_patients = pd.DataFrame(test_patients).drop(columns=[0,1])\n",
    "patients = pd.DataFrame(patients).drop(columns=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtask 1\n",
    "\n",
    "Now that the preprocessing is finished, we can start training our estimators. First, import the necessay libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_pipeline(StandardScaler(), SVC(kernel='rbf',probability=True, class_weight='balanced'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the vector containing all the labels we want to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_predict = np.array(['BaseExcess','Fibrinogen','AST','Alkalinephos','Bilirubin_total','Lactate','TroponinI','SaO2','Bilirubin_direct','EtCO2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the first prediction and initialize the vector that will contains all the predictions, initialize the vector containing the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(patients,labels_clean[0])\n",
    "probability = clf.predict_proba(test_patients)[:,1]\n",
    "\n",
    "task1_predictions = probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize data, then train the SVM and generate the AUC score, repeat this for all labels and store the predictions in the prediction vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 10 labels out of 10\r"
     ]
    }
   ],
   "source": [
    "for i in range(labels_to_predict.shape[0]-1):\n",
    "    clf.fit(patients,labels_clean[i+1])\n",
    "    probability = clf.predict_proba(test_patients)[:,1]\n",
    "    task1_predictions = np.vstack([task1_predictions,probability])\n",
    "    print('Done ' + str(i+2) + ' labels out of ' + str(labels_to_predict.shape[0]), end ='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtask 2\n",
    "\n",
    "Now we predict the occurrence of sepsis. First, create the vector containing the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_sepsis = training_labels['LABEL_Sepsis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, fit the model and add an entry to the prediction matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(patients,label_sepsis)\n",
    "task2_predictions = clf.predict_proba(test_patients)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtask 3\n",
    "\n",
    "We now want to predict the mean value of the vital sign in the remaining stay. First, let us create the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create feature vector and label vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs = training_labels.columns\n",
    "Y = training_labels[labs[12:16]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KernelRidge(alpha=0, kernel='rbf')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3 = KernelRidge(alpha=0,kernel = 'rbf')\n",
    "#Fit the model\n",
    "clf3.fit(patients,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "task3_predictions = clf3.predict(test_patients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export data to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create full prediction matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12664, 4)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task1_trans = np.transpose(task1_predictions).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pid', 'LABEL_BaseExcess', 'LABEL_Fibrinogen', 'LABEL_AST',\n",
       "       'LABEL_Alkalinephos', 'LABEL_Bilirubin_total', 'LABEL_Lactate',\n",
       "       'LABEL_TroponinI', 'LABEL_SaO2', 'LABEL_Bilirubin_direct',\n",
       "       'LABEL_EtCO2', 'LABEL_Sepsis', 'LABEL_RRate', 'LABEL_ABPm',\n",
       "       'LABEL_SpO2', 'LABEL_Heartrate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oursample = pd.read_csv('sample.csv')\n",
    "oursample.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "oursample[['LABEL_BaseExcess', 'LABEL_Fibrinogen', 'LABEL_AST','LABEL_Alkalinephos', 'LABEL_Bilirubin_total', 'LABEL_Lactate','LABEL_TroponinI', 'LABEL_SaO2', 'LABEL_Bilirubin_direct','LABEL_EtCO2']] = task1_trans[:,0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "oursample['LABEL_Sepsis'] = task2_predictions[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "oursample[['LABEL_RRate', 'LABEL_ABPm', 'LABEL_SpO2', 'LABEL_Heartrate']] = task3_predictions[:,0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "oursample.to_csv('prediction.zip', index=False, float_format='%.3f', compression='zip')\n",
    "oursample.to_csv('prediction.csv', index=False, float_format='%.3f')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (task1)",
   "language": "python",
   "name": "task1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
